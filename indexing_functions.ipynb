{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necesssary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "import os\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from geopy.geocoders import Nominatim\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining an es object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "es = Elasticsearch(['http://localhost:9200/'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the mapping and the setting for the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'test'})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"title\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"autocomplete\",\n",
    "            },\n",
    "            \"content\": {\n",
    "                \"type\": \"text\",\n",
    "            },\n",
    "            \"authors\": {\n",
    "                \"type\": \"nested\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\"type\": \"text\"},\n",
    "                },\n",
    "            },\n",
    "            \"date\": {\n",
    "                \"type\": \"date\",\n",
    "            },\n",
    "            \"geopoint\": {\n",
    "                \"type\": \"geo_point\",\n",
    "            },\n",
    "            \"temporalExpressions\": {\n",
    "                \"type\": \"text\",\n",
    "            },\n",
    "            \"georeferences\": {\n",
    "                \"type\": \"text\",\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\n",
    "                \"autocomplete\": {\n",
    "                    \"tokenizer\": \"autocomplete\",\n",
    "                    \"filter\": [\"lowercase\"]\n",
    "                },\n",
    "                \"autocomplete_search\": {\n",
    "                    \"tokenizer\": \"lowercase\"\n",
    "                }\n",
    "            },\n",
    "            \"tokenizer\": {\n",
    "                \"autocomplete\": {\n",
    "                    \"type\": \"edge_ngram\",\n",
    "                    \"min_gram\": 1,\n",
    "                    \"max_gram\": 25,\n",
    "                    \"token_chars\": [\"letter\", \"digit\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "index_name = \"test\"\n",
    "es.indices.create(index=index_name, body=index_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to extract the of publishing the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def extract_date_of_publish(reuters_tag):\n",
    "    date_obj = None\n",
    "    \n",
    "    date_tags = reuters_tag.find_all('date')\n",
    "    \n",
    "    if date_tags:\n",
    "        date_tag = date_tags[0]\n",
    "        date_str = date_tag.text.strip()\n",
    "\n",
    "        try:\n",
    "            date_obj = datetime.strptime(date_str, \"%d-%b-%Y %H:%M:%S.%f\")\n",
    "        except ValueError:\n",
    "            # Handle the case where the date string is not in the expected format\n",
    "            print(f\"Error: Unable to parse date string '{date_str}'\")\n",
    "    \n",
    "    return date_obj\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to extract the title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_article_title(reuters_tag):\n",
    "    title_tag = reuters_tag.find('title')\n",
    "    title = title_tag.text.strip() if title_tag else None\n",
    "    return title\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to extract the temporal expressions in the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_temporal_expressions(tag):\n",
    "    body_tag = tag.find('body')\n",
    "    \n",
    "    if body_tag:\n",
    "        content = body_tag.text.strip()\n",
    "        doc = nlp(content)\n",
    "        temporal_expressions = [ent.text for ent in doc.ents if ent.label_ == 'DATE']\n",
    "        return temporal_expressions\n",
    "    else:\n",
    "        return None \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to extract the authors of the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_authors(article_tag):\n",
    "    authors_tags = article_tag.find_all('author')\n",
    "    \n",
    "    authors_list = []\n",
    "    for author_tag in authors_tags:\n",
    "        author_name = author_tag.text.strip()\n",
    "        authors_list.append({\"name\": author_name})\n",
    "    \n",
    "    return authors_list if authors_list else None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to extract the georeferences in the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_georeferences(tag):\n",
    "    content_tag = tag.find('body')\n",
    "    content = content_tag.text.strip() if content_tag else None\n",
    "\n",
    "    if content:\n",
    "        doc = nlp(content)\n",
    "        georeferences = [ent.text for ent in doc.ents if ent.label_ in ['GPE', 'LOC']]\n",
    "        return georeferences\n",
    "    else:\n",
    "        return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to extract and pre proccesing the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_body(article_tag):\n",
    "    body_tag = article_tag.find('body')\n",
    "    \n",
    "    body_text = BeautifulSoup(str(body_tag), 'html.parser').get_text()\n",
    "\n",
    "    # tokenize the content\n",
    "    words = re.findall(r'\\b\\w+\\b', body_text.lower())\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_words = [word for word in words if word not in stop_words and len(word) >= 3]\n",
    "\n",
    "    porter = PorterStemmer()\n",
    "    stemmed_words = [porter.stem(word) for word in filtered_words]\n",
    "\n",
    "    # join the processed words back into a string\n",
    "    processed_body = ' '.join(stemmed_words)\n",
    "\n",
    "    return processed_body\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to convert the geo references into geopoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_geopoints(georeferences):\n",
    "    geolocator = Nominatim(user_agent=\"your_user_agent_here\")\n",
    "    coordinates = []\n",
    "\n",
    "    for georef in georeferences:\n",
    "        if georef and isinstance(georef, str):\n",
    "            location = geolocator.geocode(georef)\n",
    "            if location and hasattr(location, 'latitude') and hasattr(location, 'longitude'):\n",
    "                coordinates.append({\n",
    "                    \"lat\": location.latitude,\n",
    "                    \"lon\": location.longitude\n",
    "                })\n",
    "\n",
    "    return coordinates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to extract and index all attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_document(title, content, authors, date, geopoint, temporal_expressions, georeferences):\n",
    "    try:\n",
    "        # Ensure that required fields have valid values before indexing\n",
    "        if title and content:\n",
    "            document = {\n",
    "                'title': title,\n",
    "                'content': content,\n",
    "                'authors': authors,\n",
    "                'date': date,\n",
    "                'geopoint': geopoint,\n",
    "                'temporalExpressions': temporal_expressions,\n",
    "                'georeferences': georeferences\n",
    "            }\n",
    "\n",
    "            # Index the document\n",
    "            es.index(index='test', body=document)\n",
    "            print(f\"Document indexed successfully: {title}\")\n",
    "        else:\n",
    "            print(\"Skipping document due to missing required fields.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error indexing document: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document indexed successfully: BAHIA COCOA REVIEW\n",
      "Document indexed successfully: STANDARD OIL <SRD> TO FORM FINANCIAL UNIT\n",
      "Document indexed successfully: TEXAS COMMERCE BANCSHARES <TCB> FILES PLAN\n",
      "Document indexed successfully: TALKING POINT/BANKAMERICA <BAC> EQUITY OFFER\n",
      "Document indexed successfully: NATIONAL AVERAGE PRICES FOR FARMER-OWNED RESERVE\n",
      "Document indexed successfully: ARGENTINE 1986/87 GRAIN/OILSEED REGISTRATIONS\n",
      "Document indexed successfully: RED LION INNS FILES PLANS OFFERING\n",
      "Document indexed successfully: USX <X> DEBT DOWGRADED BY MOODY'S\n",
      "Document indexed successfully: CHAMPION PRODUCTS <CH> APPROVES STOCK SPLIT\n",
      "Document indexed successfully: COMPUTER TERMINAL SYSTEMS <CPML> COMPLETES SALE\n",
      "Document indexed successfully: COBANCO INC <CBCO> YEAR NET\n",
      "Document indexed successfully: OHIO MATTRESS <OMT> MAY HAVE LOWER 1ST QTR NET\n",
      "Document indexed successfully: AM INTERNATIONAL INC <AM> 2ND QTR JAN 31\n",
      "Document indexed successfully: BROWN-FORMAN INC <BFD> 4TH QTR NET\n",
      "Document indexed successfully: NATIONAL INTERGROUP<NII> TO OFFER PERMIAN UNITS\n",
      "Document indexed successfully: ECONOMIC SPOTLIGHT - BANKAMERICA <BAC>\n",
      "Document indexed successfully: NATIONAL HEALTH ENHANCEMENT <NHES> NEW PROGRAM\n",
      "Document indexed successfully: DEAN FOODS <DF> SEES STRONG 4TH QTR EARNINGS\n",
      "Document indexed successfully: BONUS WHEAT FLOUR FOR NORTH YEMEN  -- USDA\n",
      "Document indexed successfully: CREDIT CARD DISCLOSURE BILLS INTRODUCED\n",
      "Document indexed successfully: HUGHES CAPITAL UNIT SIGNS PACT WITH BEAR STEARNS\n",
      "Document indexed successfully: MAGMA LOWERS COPPER 0.75 CENT TO 66 CTS\n",
      "Document indexed successfully: BROWN-FORMAN <BFDB> SETS STOCK SPLIT, UPS PAYOUT\n",
      "Document indexed successfully: ESQUIRE RADIO AND ELECTRONICS INC <EE> 4TH QTR\n",
      "Document indexed successfully: SHEARSON LEHMAN NAMES NEW MANAGING DIRECTOR\n",
      "Document indexed successfully: BANKERS REPORT BREAKTHROUGH ON VENEZUELAN DEBT\n",
      "Document indexed successfully: UNITED PRESIDENTIAL CORP <UPCO> 4TH QTR NET\n",
      "Document indexed successfully: TOWER REPORT DIMINISHES REAGAN'S HOPES OF REBOUND\n",
      "Document indexed successfully: JANUARY HOUSING SALES DROP, REALTY GROUP SAYS\n",
      "Document indexed successfully: ASSETS OF MONEY MARKET MUTUAL FUNDS ROSE 720.4 MLN DLRS IN LATEST WEEK\n",
      "Document indexed successfully: U.S. TAX WRITERS SEEK ESTATE TAX CURBS, RAISING 6.7 BILLION DLRS THRU 1991\n",
      "Document indexed successfully: SENATORS INTRODUCE EXPORT LICENSING REFORM BILL\n",
      "Document indexed successfully: EXCELAN INC SETS INITIAL STOCK OFFER\n",
      "Document indexed successfully: CCX NETWORK <CCXN> SECONDARY OFFERING UNDERWAY\n",
      "Document indexed successfully: FIRST UNION <FUNC> FILES 100 MLN DLR NOTES ISSUE\n",
      "Document indexed successfully: OWENS AND MINOR INC <OBOD> RAISES QTLY DIVIDEND\n",
      "Document indexed successfully: COMPUTER LANGUAGE RESEARCH IN <CLRI> 4TH QTR\n",
      "Document indexed successfully: <CINRAM LTD> 4TH QTR NET\n",
      "Document indexed successfully: DU PONT CO <DD> LAUNCHES IMPROVED ARAMID FIBERS\n",
      "Document indexed successfully: STANDARD TRUSTCO SEES BETTER YEAR\n",
      "Document indexed successfully: HANDY AND HARMAN <HNH> 4TH QTR LOSS\n",
      "Document indexed successfully: ICO PRODUCERS TO PRESENT NEW COFFEE PROPOSAL\n",
      "Document indexed successfully: SHULTZ SAYS NO RESIGNATION OVER IRAN REPORT\n",
      "Document indexed successfully: MCLEAN'S <MII> U.S. LINES SETS ASSET TRANSFER\n",
      "Document indexed successfully: CHEMLAWN <CHEM> RISES ON HOPES FOR HIGHER BIDS\n",
      "Document indexed successfully: U.S. SUGAR IMPORTS DOWN IN WEEK - USDA\n",
      "Document indexed successfully: BRAZIL ANTI-INFLATION PLAN LIMPS TO ANNIVERSARY\n",
      "Document indexed successfully: N.Z. OFFICIAL FOREIGN RESERVES FALL IN JANUARY\n",
      "Document indexed successfully: AGENCY REPORTS 39 SHIPS WAITING AT PANAMA CANAL\n",
      "Document indexed successfully: AMERICA FIRST MORTGAGE SETS SPECIAL PAYOUT\n",
      "Document indexed successfully: REPUBLICANS EYE BIGGER U.S. CONSERVATION RESERVE\n",
      "Document indexed successfully: ARVIN INDS <ARV> PROMOTES EVANS TO PRESIDENT\n",
      "Document indexed successfully: EMHART CORP <EMH> QTLY DIVIDEND\n",
      "Document indexed successfully: U.S. DATA POINT TO CAPITAL SPENDING SLOWDOWN\n",
      "Document indexed successfully: SENATORS INTRODUCE EXPORT LICENSING REFORM BILL\n",
      "Document indexed successfully: AM INTERNATIONAL <AM> CITES STRONG PROSPECTS\n",
      "Document indexed successfully: CCC CREDITS FOR HONDURAS SWITCHED TO WHITE CORN\n",
      "Document indexed successfully: ASSETS OF U.S. MONEY FUNDS ROSE IN WEEK\n",
      "Document indexed successfully: GULF BARGE FREIGHT RATES UP FURTHER ON CALL\n",
      "Document indexed successfully: ARGENTINA COULD SUSPEND DEBT PAYMENTS - DEPUTY\n",
      "Document indexed successfully: KEY U.S. TAX WRITERS SEEK ESTATE TAX CURBS\n",
      "Document indexed successfully: TREASURY BALANCES AT FED ROSE ON FEB 25\n",
      "Document indexed successfully: CANADA'S WILSON SEEKS TEMPORARY BORROWING\n",
      "Document indexed successfully: GULF APPLIED <GATS> SELLS UNITS, SEES GAIN\n",
      "Document indexed successfully: FARMERS GROUP INC <FGRP> 4TH QTR NET\n",
      "Document indexed successfully: POTOMAC ELECTRIC POWER CO <POM> JAN NET\n",
      "Document indexed successfully: SPRINGBOARD <SPBD> IN DEAL\n",
      "Document indexed successfully: <COFAB INC> BUYS GULFEX FOR UNDISCLOSED AMOUNT\n",
      "Document indexed successfully: U.S. WEEKLY SOYBEAN CRUSH 21,782,929 BUSHELS\n",
      "Document indexed successfully: SCHULT HOMES OFFERING PRICED AT FIVE DLRS/UNIT\n",
      "Document indexed successfully: TULTEX CORP <TTX> SETS QUARTERLY DIVIDEND\n",
      "Document indexed successfully: BURLINGTON <BUR>  GETS 30.5 MLN DLR CONTRACT\n",
      "Document indexed successfully: ROCKWELL <ROK> GETS 28.3 MLN DLR B-1 CONTRACT\n",
      "Document indexed successfully: ATICO FINANCIAL CORP <ATFC> 4TH QTR NET\n",
      "Document indexed successfully: ICO EXPORTERS TO MODIFY NEW PROPOSAL\n",
      "Document indexed successfully: U.S. COMMERCIAL PAPER FALLS 375 MLN DLRS IN FEB 18 WEEK, FED SAYS\n",
      "Document indexed successfully: N.Y. BUSINESS LOANS FALL 195 MLN DLRS IN FEB 18 WEEK, FED SAYS\n",
      "Document indexed successfully: NEW YORK BANK DISCOUNT WINDOW BORROWINGS 64 MLN DLRS IN FEB 25 WEEK\n",
      "Document indexed successfully: QUEBECOR <PQB> HEAD SEES NEW VENTURES LIKELY\n",
      "Document indexed successfully: NEW YORK BUSINESS LOANS FALL 195 MLN DLRS\n",
      "Document indexed successfully: N.Y. BANK DISCOUNT BORROWINGS 64 MLN DLRS\n",
      "Document indexed successfully: PHILIPPINE LONG DISTANCE <PHI> YEAR NET\n",
      "Document indexed successfully: LIBERTY ALL-STAR EQUITY FUND INITIAL DIV\n",
      "Document indexed successfully: COLUMBIA GAS SYSTEM INC <CG> REDEEMS DEBENTURES\n",
      "Document indexed successfully: COMBUSTION ENGINEERING INC <CSP> REGULAR DIV\n",
      "Document indexed successfully: TONKA CORP <TKA> RAISES DIVIDEND\n",
      "Document indexed successfully: BDM INTERNATIONAL <BDM> INCREASES QTRLY DIVS\n",
      "Document indexed successfully: SORG <SRG> STOCKHOLDERS FORM GROUP\n",
      "Document indexed successfully: SYSTEMATICS INC <SYST> REGULAR PAYOUT\n",
      "Document indexed successfully: TEXAS INSTRUMENTS <TXN> DEVELOPS NEW CHIP\n",
      "Document indexed successfully: CONSOLIDATED GAS <CNG>UNIT SAYS NO RULES BROKEN\n",
      "Document indexed successfully: U.S. M-1 MONEY SUPPLY RISES 2.1 BILLION DLRS IN FEB 16 WEEK, FED SAYS\n",
      "Document indexed successfully: <IVACO INC> YEAR NET\n",
      "Document indexed successfully: U.S. BANK DISCOUNT BORROWINGS AVERAGE 310 MLN DLRS IN FEB 25 WEEK, FED SAYS\n",
      "Document indexed successfully: U.S. BANK NET FREE RESERVES 644 MLN DLRS IN TWO WEEKS TO FEB 25, FED SAYS\n",
      "Document indexed successfully: INVESTMENT FIRMS CUT CYCLOPS <CYL> STAKE\n",
      "Document indexed successfully: ASCS TERMINAL MARKET VALUES FOR PIK GRAIN\n",
      "Document indexed successfully: CORADIAN CORP <CDIN> 4TH QTR NET\n",
      "Skipping document due to missing required fields.\n",
      "Document indexed successfully: N.Z. TRADING BANK DEPOSIT GROWTH RISES SLIGHTLY\n",
      "Skipping document due to missing required fields.\n",
      "Skipping document due to missing required fields.\n",
      "Skipping document due to missing required fields.\n",
      "Document indexed successfully: WORLD MARKET PRICE FOR UPLAND COTTON - USDA\n",
      "Document indexed successfully: SUGAR QUOTA IMPORTS DETAILED -- USDA\n",
      "Document indexed successfully: GRAIN SHIPS LOADING AT PORTLAND\n",
      "Document indexed successfully: IRAN ANNOUNCES END OF MAJOR OFFENSIVE IN GULF WAR\n",
      "Document indexed successfully: MERIDIAN BANCORP INC <MRDN> SETS REGULAR PAYOUT\n",
      "Document indexed successfully: U.S. BANK DISCOUNT BORROWINGS 310 MLN DLRS\n",
      "Document indexed successfully: AMERICAN EXPRESS <AXP> SEEN IN POSSIBLE SPINNOFF\n",
      "Document indexed successfully: U.S. M-1 MONEY SUPPLY ROSE 2.1 BILLION DLRS\n",
      "Document indexed successfully: GENERAL BINDING <GBND> IN MARKETING AGREEMENT\n",
      "Document indexed successfully: LIBERTY ALL-STAR <USA> SETS INITIAL PAYOUT\n",
      "Document indexed successfully: COCA COLA <KO> UNIT AND WORLD FILM IN VENTURE\n",
      "Document indexed successfully: FORD MOTOR CREDIT <F> TO REDEEM DEBENTURES\n",
      "Document indexed successfully: STERLING SOFTWARE <SSW> NOTE HOLDERS OK BUY\n",
      "Document indexed successfully: <SCHULT HOMES CORP> MAKES INITIAL STOCK OFFER\n",
      "Document indexed successfully: FLUOR <FLR> UNIT GETS CONSTRUCTION CONTRACT\n",
      "Document indexed successfully: SUFFIELD FINANCIAL CORP <SFCP> SELLS STOCK\n",
      "Document indexed successfully: <HIGH POINT FINANCIAL CORP> SETS OFFERING\n",
      "Document indexed successfully: CHINESE PORK OUTPUT SEEN LOWER -- USDA\n",
      "Document indexed successfully: LANDMARK BANCSHARES <LBC> TO BE LISTED ON NYSE\n",
      "Document indexed successfully: IVACO SEES MINIMAL FIRST QUARTER EARNINGS\n",
      "Document indexed successfully: U.S. GRAIN CARLOADINGS FALL IN WEEK\n",
      "Document indexed successfully: HONG KONG FIRM UPS WRATHER<WCO> STAKE TO 11 PCT\n",
      "Document indexed successfully: COLECO INDUSTRIES INC <CLO> 4TH QTR\n",
      "Document indexed successfully: DIAMOND SHAMROCK (DIA) CUTS CRUDE PRICES\n",
      "Document indexed successfully: LIEBERT CORP <LIEB> APPROVES MERGER\n",
      "Document indexed successfully: NORTHERN TELECOM PROPOSES TWO-FOR-ONE STOCK SPLIT\n",
      "Document indexed successfully: COLECO INDUSTRIES <CLC> SEES PROFIT IN 1987\n",
      "Document indexed successfully: OLIN CORP <OLM> TO ELECT NEW CEO IN APRIL\n",
      "Skipping document due to missing required fields.\n",
      "Skipping document due to missing required fields.\n",
      "Document indexed successfully: GULF APPLIED TECHNOLOGIES <GATS> SELLS UNITS\n",
      "Document indexed successfully: INVESTMENT GROUP RAISES ROBESON <RBSN> STAKE\n",
      "Document indexed successfully: GAO LIKELY TO SHOW CERTS MORE COSTLY THAN CASH\n",
      "Document indexed successfully: Venezuela seeks 'flexibility' from banks-azpurua\n",
      "Document indexed successfully: DAHLBERG INC <DAHL> 4TH QTR NET\n",
      "Document indexed successfully: CITY NATIONAL CORP <CTYN> RAISES DIVIDEND\n",
      "Document indexed successfully: <PAGE PETROLEUM LTD> YEAR LOSS\n",
      "Document indexed successfully: THOMSON MCKINNON UNIT'S CMO OFFERING PRICED\n",
      "Document indexed successfully: IDB COMMUNICATIONS GROUP INC <IDBX> YEAR NET\n",
      "Document indexed successfully: ARMOR ALL PRODUCTS CORP <ARMR> QUARTERLY DIV\n",
      "Document indexed successfully: OPEC MAY HAVE TO MEET TO FIRM PRICES - ANALYSTS\n",
      "Document indexed successfully: CENERGY <CRG> REPORTS 4TH QTR NET PROFIT\n",
      "Document indexed successfully: NORTHERN TELECOM LTD <NT> DECLARES STOCK SPLIT\n",
      "Document indexed successfully: TORCHMARK <TMK> AUTHORIZES STOCK REPURCHASE\n",
      "Document indexed successfully: PAINEWEBBER GROUP <PWJ> TO REDEEM DEBENTURES\n",
      "Document indexed successfully: R.P. SCHERER <SCHC> SETS PREFERRED STOCK OFFER\n",
      "Document indexed successfully: PARLUX FRAGRANCES COMPLETES INITIAL OFFERING\n",
      "Document indexed successfully: TECHAMERICA GROUP INC <TCH> 4TH QTR LOSS\n",
      "Document indexed successfully: WILFRED AMERICAN EDUCATIONAL <WAE> REGULAR DIV\n",
      "Document indexed successfully: DREXEL OFFICIAL HAS STAKE IN EPSILON DATA <EPSI>\n",
      "Document indexed successfully: PROPOSED OFFERINGS RECENTLY FILED WITH THE SEC\n",
      "Document indexed successfully: VARIAN <VAR>, SIEMENS FORM JOINT VENTURE\n",
      "Document indexed successfully: DU PONT <DD> WINS SUIT AGAINST PHILLIPS <P>\n",
      "Document indexed successfully: <NOVA> WINS GOVERNMENT OKAY FOR HUSKY <HYO> DEAL\n",
      "Document indexed successfully: PRESIDENTIAL AIRWAYS <PAIR> PACT APPROVED\n",
      "Document indexed successfully: ARMY TO RENEGOTIATE ITT <ITT> RADIO CONTRACT\n",
      "Document indexed successfully: POTOMAC ELECTRIC POWER CO <POM> JANUARY NET\n",
      "Document indexed successfully: TORCHMARK <TMK> SELLS SINKING FUND DEBENTURES\n",
      "Document indexed successfully: SUFFIELD FINANCIAL <SSBK> GETS FED APPROVAL\n",
      "Document indexed successfully: AFG INDUSTRIES INC <AFG> QUARTERLY DIVIDEND\n",
      "Document indexed successfully: <GSW INC> YEAR NET\n",
      "Document indexed successfully: SANTA ANITA REALTY <SAR> QUARTERLY DIVIDEND\n",
      "Document indexed successfully: LIQUID AIR CORP <LANA> QUARTERLY DIVIDEND\n",
      "Document indexed successfully: (MARSHALL STEEL LTD) YEAR NET\n",
      "Document indexed successfully: MARSHALL STEEL DETAILS GAIN FROM UNIT SALE\n",
      "Document indexed successfully: MAYFAIR INDUSTRIES INC <MAYF> 4TH QTR NET\n",
      "Document indexed successfully: (CORRECTED) - BANPONCE <BDEP> PLACES NOTES\n",
      "Document indexed successfully: U.S. TREASURY SAYS IT WILL PARTICIPATE WITH OTHERS IN 500 MLN DLR BRIDGE LOAN TO ARGENTINA\n",
      "Document indexed successfully: U.S. REGULATOR CLOSES BANKS IN TEXAS, LOUISIANA\n",
      "Document indexed successfully: OLIN <OLN> NAMES SUCCESSOR FOR CHIEF EXECUTIVE\n",
      "Document indexed successfully: DAEWOO MOTOR TO BOOST IMPORTS OF U.S. GOODS\n",
      "Document indexed successfully: BANKS EXPRESS GRAVE CONCERN ON BRAZIL DEBT MOVES\n",
      "Document indexed successfully: LNG IMPORTS FROM ALGERIA UNLIKELY IN 1987\n",
      "Document indexed successfully: U.S. FARM CREDIT RESCUE BILL SEEN BEFORE EASTER\n",
      "Document indexed successfully: REPORT COULD BE FINAL BLOW FOR REGAN\n",
      "Document indexed successfully: SWISS ECONOMY IN EXCELLENT CONDITION, OECD SAYS\n",
      "Document indexed successfully: U.S. WHEAT BONUS TO SOVIET CALLED DORMANT\n",
      "Document indexed successfully: U.S. TREASURY PART OF ARGENTINE BRIDGE LOAN\n",
      "Document indexed successfully: COMPANIES SET BID FOR CANADA HELICOPTER CONTRACT\n",
      "Document indexed successfully: ALATENN RESOURCES INC <ATNG> 4TH QTR NET\n",
      "Document indexed successfully: AMERICAN TRAVELLERS <ATVC> EXPANDS OPERATIONS\n",
      "Document indexed successfully: VERSATILE TO SELL UNIT TO VICON\n",
      "Document indexed successfully: VIDEOTRON BUYS INTO EXHIBIT COMPANY\n",
      "Document indexed successfully: <MEMOTEC DATA INC> YEAR NET\n",
      "Document indexed successfully: ROHR INDUSTRIES <RHR> SETTLES STRIKE\n",
      "Document indexed successfully: TEXACO CANADA CUTS CRUDE PRICES 64 CANADIAN CTS/BBL, PAR GRADE TO 22.26 CANADIAN DLRS\n",
      "Document indexed successfully: BANKS EXPRESS GRAVE CONCERN ON BRAZIL DEBT MOVE\n",
      "Document indexed successfully: TEXACO CANADA <TXC> LOWERS CRUDE POSTINGS\n",
      "Document indexed successfully: JURY FINDS FOR DOW <DOW> IN BIRTH DEFECT CASE\n",
      "Document indexed successfully: USDA SAID UNLIKELY TO BROADEN CORN BONUS OFFER\n",
      "Document indexed successfully: MARATHON PETROLEUM REDUCES CRUDE POSTINGS\n",
      "Document indexed successfully: AGENCY VOTES TO END LOCAL NUCLEAR PLANT VETO\n",
      "Document indexed successfully: <GEORGE WESTON LTD> YEAR NET\n",
      "Document indexed successfully: RELIEF TO U.S. CORN/OATS GROWERS SAID LIKELY\n",
      "Document indexed successfully: N.Z. MONEY SUPPLY RISES 3.6 PCT IN DECEMBER\n",
      "Document indexed successfully: CIRCUIT SYSTEMS <CSYI> BUYS BOARD MAKER\n",
      "Document indexed successfully: FALLING SOYBEAN CRUSH RATIOS CUT OUTPUT\n",
      "Document indexed successfully: MAIL BOXES ETC <MAIL> 3RD QTR JAN 31 NET\n",
      "Document indexed successfully: MUNSINGWEAR INC <MUN> 4TH QTR JAN 3 LOSS\n",
      "Document indexed successfully: FED DATA SUGGEST STABLE U.S. MONETARY POLICY\n",
      "Document indexed successfully: FEDERAL INDUSTRIES LAUNCHES EUROBOND ISSUE\n",
      "Document indexed successfully: NYSE TO STUDY REGULATION OF SECURITY INDUSTRY\n",
      "Document indexed successfully: KOREAN AIR ORDERS MCDONNELL DOUGLAS <MD> MD-11S\n",
      "Document indexed successfully: DELTA ROCKET BLASTS OFF FROM CAPE CANAVERAL\n",
      "Document indexed successfully: JAPAN TO TRY TO OPEN MARKET TO U.S. CAR PARTS\n",
      "Document indexed successfully: FRANCE FACES PRESSUE TO CHANGE POLICIES\n",
      "Document indexed successfully: GTI CORP <GTI> 4TH QTR OPER NET\n",
      "Document indexed successfully: HOUSTON OIL <HO> RESERVES STUDY COMPLETED\n",
      "Document indexed successfully: FAMOUS RESTAURANTS INC <FAMS> 4TH QTR LOSS\n",
      "Document indexed successfully: JAPAN CONSUMER PRICES FALL 0.4 PCT IN JANUARY\n",
      "Document indexed successfully: AVERY <AVY> SETS TWO FOR ONE STOCK SPLIT\n",
      "Document indexed successfully: MICROSOFT CORP <MSFT> HALTS MS-DOS IMPORTS\n",
      "Skipping document due to missing required fields.\n",
      "Document indexed successfully: JAPAN MARCH BOND COUPON SEEN UNCHANGED AT FIVE PCT\n",
      "Document indexed successfully: U.S. LAUNCHES WEATHER SATELLITE\n",
      "Document indexed successfully: ITALIAN COALITION MEETS AS GOVERNMENT CRISIS LOOMS\n",
      "Document indexed successfully: N.Z. CENTRAL BANK SEES SLOWER MONEY, CREDIT GROWTH\n",
      "Document indexed successfully: AVERAGE YEN CD RATES FALL IN LATEST WEEK\n",
      "Document indexed successfully: BRITAIN'S ALLIANCE OPPOSITION WINS BY-ELECTION\n",
      "Document indexed successfully: ECONOMIC SPOTLIGHT - JAPAN EYEING FOREIGN STOCKS\n",
      "Document indexed successfully: TAIWAN OFFSHORE BANKING ASSETS RISE IN JANUARY\n",
      "Document indexed successfully: JAPAN EXPECTED TO CUT BASE RATE FOR STATE BODIES\n",
      "Document indexed successfully: JAPAN HOUSE BUDGET TALKS TO REOPEN NEXT WEEK\n",
      "Document indexed successfully: AUSTRALIA'S KEATING CHANGES ECONOMIC FORECASTS\n",
      "Document indexed successfully: THAI RICE EXPORTS RISE IN WEEK ENDED FEBRUARY 24\n",
      "Document indexed successfully: TOKYO GRAIN EXCHANGE TO RAISE MARGIN REQUIREMENTS\n",
      "Document indexed successfully: MANILA SAID TO OFFER DEBT BONDS TO BANKS\n",
      "Document indexed successfully: POLL MAJORITY DISAPPROVE OF REAGAN PRESIDENCY\n",
      "Document indexed successfully: PRODUCER SPLIT HEATS UP COFFEE QUOTA TALKS\n",
      "Document indexed successfully: ITALIAN TREASURY CUTS INTEREST ON CERTIFICATES\n",
      "Document indexed successfully: BRITISH CONSERVATIVES AHEAD OF LABOUR IN NEW POLLS\n",
      "Document indexed successfully: INDONESIAN AGRICULTURE GROWTH EXPECTED TO SLOW\n",
      "Document indexed successfully: KUWAIT SAYS NO PLANS FOR EMERGENCY OPEC TALKS\n",
      "Document indexed successfully: INDONESIA SEEN AT CROSSROADS OVER ECONOMIC CHANGE\n",
      "Document indexed successfully: INDIAN BUDGET COMES IN FOR WIDE CRITICISM\n",
      "Document indexed successfully: CHINA TO BORROW 390 MLN DLRS\n",
      "Document indexed successfully: MANILA SAID TO OFFER DEBT BONDS TO BANKS\n",
      "Document indexed successfully: CHINESE WHEAT CROP THREATENED BY PESTS, DISEASE\n",
      "Document indexed successfully: SAUDI RIYAL DEPOSIT RATES REMAIN FIRM\n",
      "Document indexed successfully: IRAN CLAIMS NEW VICTORIES NEAR BASRA\n",
      "Document indexed successfully: BANGLADESH MOVES AGAINST LOAN DEFAULTERS\n",
      "Document indexed successfully: IRAQ SAYS IT REPELS IRANIAN ATTACK\n",
      "Document indexed successfully: QATAR UNVEILS BUDGET FOR FISCAL 1987/88\n",
      "Document indexed successfully: GULF BOND, STOCK MARKETS LAG BEHIND, GIB SAYS\n",
      "Document indexed successfully: SAUDI ARABIA REITERATES COMMITMENT TO OPEC PACT\n",
      "Document indexed successfully: COFFEE QUOTA TALKS CONTINUE, NO ACCORD SEEN LIKELY\n",
      "Document indexed successfully: NEW ZEALAND CANCELS WEEKLY T-BILL TENDER\n",
      "Document indexed successfully: SHARE TRADING IN CHEUNG KONG GROUP SUSPENDED\n",
      "Document indexed successfully: FEBRUARY U.S. PURCHASING MANAGER INDEX FALLS\n",
      "Document indexed successfully: CANADA-EGYPT WHEAT NEGOTIATIONS TO CONTINUE\n",
      "Document indexed successfully: INDONESIAN WHEAT IMPORTS EXPECTED TO FALL IN 1987\n",
      "Document indexed successfully: SHULTZ LIKELY TO VISIT MOSCOW SOON\n",
      "Document indexed successfully: ZAMBIA TO RETAIN CURRENCY AUCTION, SAYS KAUNDA\n",
      "Document indexed successfully: POLISH BANKER PLEASED WITH WORLD BANK, IMF TALKS\n",
      "Document indexed successfully: RECORD N.Z. FUTURES VOLUMES TRADED IN FEBRUARY\n",
      "Document indexed successfully: INDONESIAN SUGAR OUTPUT SEEN SHORT OF TARGET\n",
      "Document indexed successfully: NIPPON KOKAN STEEL AFFILIATES CONSIDERING MERGER\n",
      "Document indexed successfully: Qantas Airways says will buy four Boeing 747-400's for one billion Australian\n",
      "Document indexed successfully: EGYPT TO HOST NINE-NATION AFRICAN TALKS THIS MONTH\n",
      "Document indexed successfully: EC MINISTERS CONSIDER BIG AGRICULTURE PRICE CUTS\n",
      "Document indexed successfully: QANTAS TO BUY FOUR 747-400'S FOR ONE BILLION DLRS\n",
      "Document indexed successfully: IEL SETS 100 MLN DLR NOTE/COMMERCIAL PAPER ISSUE\n",
      "Document indexed successfully: AMERICAN EXPRESS STUDIES OPTIONS FOR SHEARSON\n",
      "Document indexed successfully: INDONESIA UNLIKELY TO IMPORT PHILIPPINES COPRA\n",
      "Document indexed successfully: SRI LANKAN BANK OFFERS 250 MLN RUPEES T-BILLS\n",
      "Document indexed successfully: STRONG EARTHQUAKE HITS NEW ZEALAND\n",
      "Document indexed successfully: PHILIPPINES HEADS CONFIDENTLY INTO DEBT TALKS\n",
      "Document indexed successfully: JAPAN FEBRUARY INTERIM TRADE SURPLUS JUMPS\n",
      "Document indexed successfully: NIPPON LIGHT METAL CONTINUES ALUMINIUM OUTPUT CUT\n",
      "Document indexed successfully: SAUDI FEBRUARY CRUDE OUTPUT PUT AT 3.5 MLN BPD\n",
      "Document indexed successfully: INDONESIAN PALM OIL OUTPUT EXPECTED TO RISE\n",
      "Document indexed successfully: INDONESIAN TEA, COCOA EXPORTS SEEN UP, COFFEE DOWN\n",
      "Document indexed successfully: SINGAPORE EXCHANGE SEEKING NASDAQ/LONDON LINK\n",
      "Document indexed successfully: INDONESIA'S EXPORTS DROP IN CALENDAR 1986\n",
      "Document indexed successfully: GERMAN EUROBOND MARKET EXPECTS BREATHING SPACE\n",
      "Document indexed successfully: JAPAN'S NTT FORECASTS PROFITS FALL IN 1987/88\n",
      "Document indexed successfully: SINO-U.S. VENTURE IN CHINA TO MAKE RINSING AGENTS\n",
      "Document indexed successfully: CHINA SIGNS WORLD BANK LOAN FOR TIANJIN PORT\n",
      "Document indexed successfully: THAI AIRWAYS INTERNATIONAL TO ALMOST DOUBLE FLEET\n",
      "Document indexed successfully: Japan February external reserves record 51.73 billion dlrs (January 51.46 billion)\n",
      "Document indexed successfully: JAPAN FEBRUARY RESERVES RECORD 51.73 BILLION DLRS\n",
      "Document indexed successfully: SIMEX TRADING VOLUME HITS RECORD IN FEBRUARY\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m         index_document(title, body, authors, date, geopoints, temporal_expressions, georeferences)        \n\u001b[0;32m     25\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 26\u001b[0m \u001b[43mprocess_sgm_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[22], line 5\u001b[0m, in \u001b[0;36mprocess_sgm_folder\u001b[1;34m(folder_path)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.sgm\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      4\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, filename)\n\u001b[1;32m----> 5\u001b[0m     \u001b[43mprocess_sgm_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[22], line 21\u001b[0m, in \u001b[0;36mprocess_sgm_file\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     19\u001b[0m temporal_expressions \u001b[38;5;241m=\u001b[39m extract_temporal_expressions(reuters_tag)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m georeferences \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 21\u001b[0m     geopoints \u001b[38;5;241m=\u001b[39m \u001b[43mextract_geopoints\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeoreferences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m index_document(title, body, authors, date, geopoints, temporal_expressions, georeferences)\n",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m, in \u001b[0;36mextract_geopoints\u001b[1;34m(georeferences)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m georef \u001b[38;5;129;01min\u001b[39;00m georeferences:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m georef \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(georef, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m----> 7\u001b[0m         location \u001b[38;5;241m=\u001b[39m \u001b[43mgeolocator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeocode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeoref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m location \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(location, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(location, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      9\u001b[0m             coordinates\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     10\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m\"\u001b[39m: location\u001b[38;5;241m.\u001b[39mlatitude,\n\u001b[0;32m     11\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m\"\u001b[39m: location\u001b[38;5;241m.\u001b[39mlongitude\n\u001b[0;32m     12\u001b[0m             })\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\geopy\\geocoders\\nominatim.py:297\u001b[0m, in \u001b[0;36mNominatim.geocode\u001b[1;34m(self, query, exactly_one, timeout, limit, addressdetails, language, geometry, extratags, country_codes, viewbox, bounded, featuretype, namedetails)\u001b[0m\n\u001b[0;32m    295\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.geocode: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, url)\n\u001b[0;32m    296\u001b[0m callback \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_json, exactly_one\u001b[38;5;241m=\u001b[39mexactly_one)\n\u001b[1;32m--> 297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_geocoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\geopy\\geocoders\\base.py:368\u001b[0m, in \u001b[0;36mGeocoder._call_geocoder\u001b[1;34m(self, url, callback, timeout, is_json, headers)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_json:\n\u001b[1;32m--> 368\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq_headers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapter\u001b[38;5;241m.\u001b[39mget_text(url, timeout\u001b[38;5;241m=\u001b[39mtimeout, headers\u001b[38;5;241m=\u001b[39mreq_headers)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\geopy\\adapters.py:472\u001b[0m, in \u001b[0;36mRequestsAdapter.get_json\u001b[1;34m(self, url, timeout, headers)\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_json\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, \u001b[38;5;241m*\u001b[39m, timeout, headers):\n\u001b[1;32m--> 472\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    474\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\geopy\\adapters.py:482\u001b[0m, in \u001b[0;36mRequestsAdapter._request\u001b[1;34m(self, url, timeout, headers)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, \u001b[38;5;241m*\u001b[39m, timeout, headers):\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 482\u001b[0m         resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m    484\u001b[0m         message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(error)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\sessions.py:602\u001b[0m, in \u001b[0;36mSession.get\u001b[1;34m(self, url, **kwargs)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[0;32m    595\u001b[0m \n\u001b[0;32m    596\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;124;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    601\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    787\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    806\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    460\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 461\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:1386\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1385\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1386\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1387\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1388\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:286\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 286\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\ssl.py:1315\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1312\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1313\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1314\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def process_sgm_folder(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".sgm\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            process_sgm_file(file_path)\n",
    "\n",
    "def process_sgm_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        \n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    reuters_tags = soup.find_all('reuters')\n",
    "    for reuters_tag in reuters_tags:      \n",
    "        date=extract_date_of_publish(reuters_tag)\n",
    "        authors=extract_authors(reuters_tag)\n",
    "        title = extract_article_title(reuters_tag)\n",
    "        body = preprocess_body(reuters_tag)\n",
    "        georeferences = extract_georeferences(reuters_tag)\n",
    "        temporal_expressions = extract_temporal_expressions(reuters_tag)\n",
    "        if georeferences is not None:\n",
    "            geopoints = extract_geopoints(georeferences)\n",
    "        \n",
    "        index_document(title, body, authors, date, geopoints, temporal_expressions, georeferences)        \n",
    "\n",
    "data = \"data\"\n",
    "process_sgm_folder(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1- Title: COCA COLA <KO> UNIT AND WORLD FILM IN VENTURE, Score: 33.69805\n",
      "2- Title: BAHIA COCOA REVIEW, Score: 23.156023\n",
      "3- Title: COLECO INDUSTRIES INC <CLO> 4TH QTR, Score: 19.444569\n",
      "4- Title: INDONESIAN TEA, COCOA EXPORTS SEEN UP, COFFEE DOWN, Score: 18.78078\n",
      "5- Title: COLECO INDUSTRIES <CLC> SEES PROFIT IN 1987, Score: 17.946524\n",
      "6- Title: COLUMBIA GAS SYSTEM INC <CG> REDEEMS DEBENTURES, Score: 17.190845\n",
      "7- Title: CORADIAN CORP <CDIN> 4TH QTR NET, Score: 6.8717756\n",
      "8- Title: COMPUTER TERMINAL SYSTEMS <CPML> COMPLETES SALE, Score: 6.1670065\n",
      "9- Title: COMPANIES SET BID FOR CANADA HELICOPTER CONTRACT, Score: 6.0839787\n",
      "10- Title: FLUOR <FLR> UNIT GETS CONSTRUCTION CONTRACT, Score: 6.0172753\n"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell_checker = SpellChecker()\n",
    "\n",
    "# Function to correct spelling in a sentence\n",
    "def correct_spelling(sentence):\n",
    "    corrected_words = [spell_checker.correction(word) for word in sentence.split()]\n",
    "    return ' '.join(corrected_words)\n",
    "\n",
    "# Example user input\n",
    "user_input = \"coce cola\"\n",
    "\n",
    "# Correct spelling in the user input\n",
    "corrected_query = correct_spelling(user_input)\n",
    "\n",
    "# Check if the corrected query is at least three characters\n",
    "if len(corrected_query) >= 3:\n",
    "    autocomplete_query = {\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"title\": {\n",
    "                    \"query\": corrected_query,\n",
    "                    \"fuzziness\": \"AUTO\",  # Enable fuzzy matching\n",
    "                    \"prefix_length\": 3,   # Adjust as needed\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    autocomplete_result = es.search(index=\"test\", body=autocomplete_query)\n",
    "\n",
    "    # Print ranked titles and scores\n",
    "    for idx, hit in enumerate(autocomplete_result[\"hits\"][\"hits\"], start=1):\n",
    "        title = hit[\"_source\"][\"title\"]\n",
    "        score = hit[\"_score\"]\n",
    "\n",
    "        print(f\"{idx}- Title: {title}, Score: {score}\")\n",
    "else:\n",
    "    print(\"User input is less than three characters. No autocomplete suggestions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "BadRequestError(400, 'search_phase_execution_exception', 'Fielddata is disabled on [georeferences] in [test]. Text fields are not optimised for operations that require per-document field data like aggregations and sorting, so these operations are disabled by default. Please use a keyword field instead. Alternatively, set fielddata=true on [georeferences] in order to load field data by uninverting the inverted index. Note that this can use significant memory.')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 14\u001b[0m\n\u001b[0;32m      2\u001b[0m aggregation_query \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggs\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_georeferences\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m     }\n\u001b[0;32m     11\u001b[0m }\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Execute the aggregation query\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m aggregation_result \u001b[38;5;241m=\u001b[39m \u001b[43mes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregation_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m aggregation_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregations\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_georeferences\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuckets\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\elasticsearch\\_sync\\client\\utils.py:402\u001b[0m, in \u001b[0;36m_rewrite_parameters.<locals>.wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    400\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m--> 402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\elasticsearch\\_sync\\client\\__init__.py:3733\u001b[0m, in \u001b[0;36mElasticsearch.search\u001b[1;34m(self, index, aggregations, aggs, allow_no_indices, allow_partial_search_results, analyze_wildcard, analyzer, batched_reduce_size, ccs_minimize_roundtrips, collapse, default_operator, df, docvalue_fields, error_trace, expand_wildcards, explain, ext, fields, filter_path, from_, highlight, human, ignore_throttled, ignore_unavailable, indices_boost, knn, lenient, max_concurrent_shard_requests, min_compatible_shard_node, min_score, pit, post_filter, pre_filter_shard_size, preference, pretty, profile, q, query, rank, request_cache, rescore, rest_total_hits_as_int, routing, runtime_mappings, script_fields, scroll, search_after, search_type, seq_no_primary_term, size, slice, sort, source, source_excludes, source_includes, stats, stored_fields, suggest, suggest_field, suggest_mode, suggest_size, suggest_text, terminate_after, timeout, track_scores, track_total_hits, typed_keys, version)\u001b[0m\n\u001b[0;32m   3731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m __body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3732\u001b[0m     __headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 3733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[0;32m   3734\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m__path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__body\u001b[49m\n\u001b[0;32m   3735\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\elasticsearch\\_sync\\client\\_base.py:320\u001b[0m, in \u001b[0;36mBaseClient.perform_request\u001b[1;34m(self, method, path, params, headers, body)\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    318\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m--> 320\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTP_EXCEPTIONS\u001b[38;5;241m.\u001b[39mget(meta\u001b[38;5;241m.\u001b[39mstatus, ApiError)(\n\u001b[0;32m    321\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage, meta\u001b[38;5;241m=\u001b[39mmeta, body\u001b[38;5;241m=\u001b[39mresp_body\n\u001b[0;32m    322\u001b[0m     )\n\u001b[0;32m    324\u001b[0m \u001b[38;5;66;03m# 'X-Elastic-Product: Elasticsearch' should be on every 2XX response.\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verified_elasticsearch:\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;66;03m# If the header is set we mark the server as verified.\u001b[39;00m\n",
      "\u001b[1;31mBadRequestError\u001b[0m: BadRequestError(400, 'search_phase_execution_exception', 'Fielddata is disabled on [georeferences] in [test]. Text fields are not optimised for operations that require per-document field data like aggregations and sorting, so these operations are disabled by default. Please use a keyword field instead. Alternatively, set fielddata=true on [georeferences] in order to load field data by uninverting the inverted index. Note that this can use significant memory.')"
     ]
    }
   ],
   "source": [
    "# Define the Elasticsearch aggregation query\n",
    "aggregation_query = {\n",
    "    \"aggs\": {\n",
    "        \"top_georeferences\": {\n",
    "            \"terms\": {\n",
    "                \"field\": \"georeferences\",\n",
    "                \"size\": 10  # Return top 10 georeferences\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Execute the aggregation query\n",
    "aggregation_result = es.search(index=\"test\", body=aggregation_query)\n",
    "aggregation_result[\"aggregations\"][\"top_georeferences\"][\"buckets\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "NotFoundError(404, 'index_not_found_exception', 'no such index [your_index_name]', your_index_name, index_or_alias)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 14\u001b[0m\n\u001b[0;32m      2\u001b[0m date_histogram_query \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggs\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocuments_over_time\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m     }\n\u001b[0;32m     11\u001b[0m }\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Execute the date histogram aggregation query\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m date_histogram_result \u001b[38;5;241m=\u001b[39m \u001b[43mes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myour_index_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_histogram_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m date_histogram_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregations\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocuments_over_time\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuckets\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\elasticsearch\\_sync\\client\\utils.py:402\u001b[0m, in \u001b[0;36m_rewrite_parameters.<locals>.wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    400\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m--> 402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\elasticsearch\\_sync\\client\\__init__.py:3733\u001b[0m, in \u001b[0;36mElasticsearch.search\u001b[1;34m(self, index, aggregations, aggs, allow_no_indices, allow_partial_search_results, analyze_wildcard, analyzer, batched_reduce_size, ccs_minimize_roundtrips, collapse, default_operator, df, docvalue_fields, error_trace, expand_wildcards, explain, ext, fields, filter_path, from_, highlight, human, ignore_throttled, ignore_unavailable, indices_boost, knn, lenient, max_concurrent_shard_requests, min_compatible_shard_node, min_score, pit, post_filter, pre_filter_shard_size, preference, pretty, profile, q, query, rank, request_cache, rescore, rest_total_hits_as_int, routing, runtime_mappings, script_fields, scroll, search_after, search_type, seq_no_primary_term, size, slice, sort, source, source_excludes, source_includes, stats, stored_fields, suggest, suggest_field, suggest_mode, suggest_size, suggest_text, terminate_after, timeout, track_scores, track_total_hits, typed_keys, version)\u001b[0m\n\u001b[0;32m   3731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m __body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3732\u001b[0m     __headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 3733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[0;32m   3734\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m__path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__body\u001b[49m\n\u001b[0;32m   3735\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\elasticsearch\\_sync\\client\\_base.py:320\u001b[0m, in \u001b[0;36mBaseClient.perform_request\u001b[1;34m(self, method, path, params, headers, body)\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    318\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m--> 320\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTP_EXCEPTIONS\u001b[38;5;241m.\u001b[39mget(meta\u001b[38;5;241m.\u001b[39mstatus, ApiError)(\n\u001b[0;32m    321\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage, meta\u001b[38;5;241m=\u001b[39mmeta, body\u001b[38;5;241m=\u001b[39mresp_body\n\u001b[0;32m    322\u001b[0m     )\n\u001b[0;32m    324\u001b[0m \u001b[38;5;66;03m# 'X-Elastic-Product: Elasticsearch' should be on every 2XX response.\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verified_elasticsearch:\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;66;03m# If the header is set we mark the server as verified.\u001b[39;00m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: NotFoundError(404, 'index_not_found_exception', 'no such index [your_index_name]', your_index_name, index_or_alias)"
     ]
    }
   ],
   "source": [
    "# Define the Elasticsearch date histogram aggregation query\n",
    "date_histogram_query = {\n",
    "    \"aggs\": {\n",
    "        \"documents_over_time\": {\n",
    "            \"date_histogram\": {\n",
    "                \"field\": \"date\",\n",
    "                \"calendar_interval\": \"1d\"  # Aggregation interval of 1 day\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Execute the date histogram aggregation query\n",
    "date_histogram_result = es.search(index=\"your_index_name\", body=date_histogram_query)\n",
    "date_histogram_result[\"aggregations\"][\"documents_over_time\"][\"buckets\"]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
